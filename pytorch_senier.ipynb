{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 本代码仅作为DeepSpeech模型的实现参考\n",
    "class BNGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BNGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, xlen):\n",
    "        maxlen = x.size(2)\n",
    "        x = self.bn(x)\n",
    "        # N×C×T -> T×N×C\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, xlen) \n",
    "        x, _ = self.gru(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x, total_length=maxlen)\n",
    "        x = x[..., :self.hidden_size] + x[..., self.hidden_size:]\n",
    "        # T×N×C -> N×C×T\n",
    "        x = x.permute(1, 2, 0)\n",
    "        return x\n",
    "\n",
    "class DeepSpeech(nn.Module):\n",
    "\n",
    "    def __init__(self, mel_channel, channels, kernel_dims, strides, \n",
    "        num_layers, hidden_size, char_size):\n",
    "\n",
    "        super(DeepSpeech, self).__init__()\n",
    "        self.kernel_dims = kernel_dims\n",
    "        self.strides = strides\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.char_size = char_size\n",
    "\n",
    "        self.cnns = nn.ModuleList()\n",
    "        in_channel = mel_channel\n",
    "        for c, k, s in zip(channels, kernel_dims, strides):\n",
    "            self.cnns.append(nn.Conv1d(in_channel, c, k, \n",
    "                stride=s, padding=c//2))\n",
    "            self.cnns.append(nn.BatchNorm1d(c))\n",
    "            self.cnns.append(nn.ReLU(inplace=True))\n",
    "            in_channel = c\n",
    "        self.cnns = nn.Sequential(*self.cnns)        \n",
    "\n",
    "        self.rnns = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.rnns.append(BNGRU(in_channel, hidden_size))\n",
    "            in_channel = hidden_size\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(hidden_size, char_size)\n",
    "        ) \n",
    "\n",
    "    def forward(self, x, xlen):\n",
    "        # T×N×C -> N×C×T\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.cnns(x)\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, xlen)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # N×C×T -> T×N×C\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        return F.log_softmax(x, -1)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BNGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BNGRU, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, xlen):\n",
    "        maxlen = x.size(2)\n",
    "        x = self.bn(x)\n",
    "        # N×C×T -> T×N×C\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, xlen) \n",
    "        x, _ = self.gru(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x, total_length=maxlen)\n",
    "        x = x[..., :self.hidden_size] + x[..., self.hidden_size:]\n",
    "        # T×N×C -> N×C×T\n",
    "        x = x.permute(1, 2, 0)\n",
    "        return x\n",
    "\n",
    "class DeepSpeech(nn.Module):\n",
    "\n",
    "    def __init__(self, mel_channel, channels, kernel_dims, strides, \n",
    "        num_layers, hidden_size, char_size):\n",
    "\n",
    "        super(DeepSpeech, self).__init__()\n",
    "        self.kernel_dims = kernel_dims\n",
    "        self.strides = strides\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.char_size = char_size\n",
    "\n",
    "        self.cnns = nn.ModuleList()\n",
    "        in_channel = mel_channel\n",
    "        for c, k, s in zip(channels, kernel_dims, strides):\n",
    "            self.cnns.append(nn.Conv1d(in_channel, c, k, \n",
    "                stride=s, padding=c//2))\n",
    "            self.cnns.append(nn.BatchNorm1d(c))\n",
    "            self.cnns.append(nn.ReLU(inplace=True))\n",
    "            in_channel = c\n",
    "        self.cnns = nn.Sequential(*self.cnns)        \n",
    "\n",
    "        self.rnns = nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            self.rnns.append(BNGRU(in_channel, hidden_size))\n",
    "            in_channel = hidden_size\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(hidden_size, char_size)\n",
    "        ) \n",
    "\n",
    "    def forward(self, x, xlen):\n",
    "        # T×N×C -> N×C×T\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.cnns(x)\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, xlen)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # N×C×T -> T×N×C\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x = self.proj(x)\n",
    "\n",
    "        return F.log_softmax(x, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 本代码仅作为DQN模型的参考实现\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gym\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, naction, nstate, nhidden):\n",
    "        super(DQN, self).__init__()\n",
    "        self.naction = naction\n",
    "        self.nstate = nstate\n",
    "        self.linear1 = nn.Linear(naction + nstate, nhidden)\n",
    "        self.linear2 = nn.Linear(nhidden, nhidden)\n",
    "        self.linear3 = nn.Linear(nhidden, 1)\n",
    "    \n",
    "    def forward(self, state, action):\n",
    "        action_enc = torch.zeros(action.size(0), self.naction)\n",
    "        action_enc.scatter_(1, action.unsqueeze(-1), 1)\n",
    "        output = torch.cat((state, action_enc), dim=-1)\n",
    "        output = torch.relu(self.linear1(output))\n",
    "        output = torch.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "class Memory(object):\n",
    "    def __init__(self, capacity=1000):\n",
    "\n",
    "        self.capacity = capacity\n",
    "        self.size = 0\n",
    "        self.data = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "        \n",
    "    def push(self, state, action, state_next, reward, is_ended):\n",
    "        \n",
    "        if len(self) > self.capacity:\n",
    "            k = random.randint(self.capacity)\n",
    "            self.data.pop(k)\n",
    "            self.size -= 1\n",
    "        \n",
    "        self.data.append((state, action, state_next, reward, is_ended))\n",
    "        \n",
    "    def sample(self, bs):\n",
    "        data = random.choices(self.data, k=bs)\n",
    "        states, actions, states_next, rewards, is_ended = zip(*data)\n",
    "        \n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions)\n",
    "        states_next = torch.tensor(states_next, dtype=torch.float32)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        is_ended = torch.tensor(is_ended, dtype=torch.float32)\n",
    "        \n",
    "        return states, actions, states_next, rewards, is_ended\n",
    "\n",
    "# 定义两个网络，用于加速模型收敛\n",
    "dqn = DQN(2, 4, 8)\n",
    "dqn_t = DQN(2, 4, 8)\n",
    "dqn_t.load_state_dict(copy.deepcopy(dqn.state_dict()))\n",
    "eps = 0.1\n",
    "# 折扣系数\n",
    "gamma = 0.999\n",
    "\n",
    "optim = torch.optim.Adam(dqn.parameters(), lr=1e-3)\n",
    "criterion = HuberLoss()         \n",
    "                      \n",
    "step_cnt = 0\n",
    "mem = Memory()\n",
    "\n",
    "for episode in range(300):\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        action_t = torch.tensor([0, 1])\n",
    "        state_t = torch.tensor([state, state], dtype=torch.float32)\n",
    "        \n",
    "        # 计算最优策略\n",
    "        torch.set_grad_enabled(False)\n",
    "        q_t = dqn(state_t, action_t)\n",
    "        max_t = q_t.argmax()\n",
    "        torch.set_grad_enabled(True)\n",
    "        \n",
    "        # 探索和利用的平衡\n",
    "        if random.random() < eps:\n",
    "            max_t = random.choice([0, 1])\n",
    "        else:\n",
    "            max_t = max_t.item()\n",
    "        \n",
    "        state_next, reward, done, info = env.step(max_t)\n",
    "        \n",
    "        mem.push(state, max_t, state_next, reward, done)\n",
    "        state = state_next\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "        # 重放训练\n",
    "        for _ in range(10):\n",
    "            state_t, action_t, state_next_t, reward_t, is_ended_t = \\\n",
    "                mem.sample(32)\n",
    "\n",
    "            q1 = dqn(state_t, action_t)\n",
    "            \n",
    "            torch.set_grad_enabled(False)\n",
    "            q2_0 = dqn_t(state_next_t, \n",
    "                         torch.zeros(state_t.size(0), dtype=torch.long))\n",
    "            q2_1 = dqn_t(state_next_t, \n",
    "                         torch.ones(state_t.size(0), dtype=torch.long))\n",
    "            # 利用Bellman方程进行迭代\n",
    "            q2_max = reward_t + gamma*(1-is_ended_t)*\n",
    "                (torch.stack((q2_0, q2_1), dim=1).max(1)[0])\n",
    "            torch.set_grad_enabled(True)\n",
    "            # 优化损失函数\n",
    "            delta = q2_max - q1\n",
    "            loss = criterion(delta)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            for p in dqn.parameters(): p.grad.data.clamp_(-1, 1)\n",
    "            optim.step()          \n",
    "            step_cnt += 1\n",
    "                            \n",
    "            # 同步两个网络的参数\n",
    "            if step_cnt % 1000 == 0:\n",
    "                dqn_t.load_state_dict(copy.deepcopy(dqn.state_dict()))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 以下代码仅为函数签名，不能实际运行\n",
    "\"\"\"\n",
    "\n",
    "# CTC损失函数\n",
    "class torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)\n",
    "\n",
    "# 对应forward方法的定义\n",
    "def forward(self, log_probs, targets, input_lengths, target_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 本代码仅供半精度模型训练的饿参考\n",
    "\"\"\"\n",
    "\n",
    "from apex.fp16_utils import *\n",
    "from apex import amp, optimizers\n",
    "\n",
    "model = Model()\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "model, optimizer = amp.initialize(model, optimizer,\n",
    "                               opt_level=args.opt_level,\n",
    "                               keep_batchnorm_fp32=args.keep_batchnorm_fp32,\n",
    "                               loss_scale=args.loss_scale)\n",
    "# ...\n",
    "loss = criterion(output, target)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "     scaled_loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 以下代码仅为Tacotron模型的一个参考实现\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Tacotron编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_n_convolutions,\n",
    "        encoder_embedding_dim, encoder_kernel_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        convolutions = []\n",
    "        for _ in range(encoder_n_convolutions):\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv1d(\n",
    "                    encoder_embedding_dim,\n",
    "                    encoder_embedding_dim,\n",
    "                    kernel_size=encoder_kernel_size, \n",
    "                    stride=1,\n",
    "                    padding=encoder_kernel_size//2,\n",
    "                         dilation=1),\n",
    "                nn.BatchNorm1d(encoder_embedding_dim))\n",
    "            convolutions.append(conv_layer)\n",
    "        self.convolutions = nn.ModuleList(convolutions)\n",
    "\n",
    "        self.lstm = nn.LSTM(encoder_embedding_dim,\n",
    "                            encoder_embedding_dim // 2, 1,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, input_lengths):\n",
    "        # 假设输入为N×C×T\n",
    "        for conv in self.convolutions:\n",
    "            x = F.dropout(F.relu(conv(x)), 0.5, self.training)\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        input_lengths = input_lengths.cpu().numpy()\n",
    "        x = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, input_lengths, batch_first=True)\n",
    "\n",
    "        self.lstm.flatten_parameters()\n",
    "        outputs, _ = self.lstm(x)\n",
    "\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "            outputs, batch_first=True)\n",
    "        return outputs\n",
    "\n",
    "# Tacotron前处理/后处理代码\n",
    "class Prenet(nn.Module):\n",
    "    def __init__(self, in_dim, sizes):\n",
    "        super(Prenet, self).__init__()\n",
    "        in_sizes = [in_dim] + sizes[:-1]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(in_size, out_size, bias=False)\n",
    "             for (in_size, out_size) in zip(in_sizes, sizes)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for linear in self.layers:\n",
    "            x = F.dropout(F.relu(linear(x)), p=0.5, training=True)\n",
    "        return x\n",
    "\n",
    "class Postnet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_mel_channels, postnet_embedding_dim,\n",
    "            postnet_kernel_size, postnet_n_convolutions):\n",
    "\n",
    "        super(Postnet, self).__init__()\n",
    "        self.convolutions = nn.ModuleList()\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(n_mel_channels, postnet_embedding_dim,\n",
    "                          kernel_size=postnet_kernel_size, stride=1,\n",
    "                          padding=postnet_kernel_size // 2),\n",
    "                          dilation=1),\n",
    "                nn.BatchNorm1d(postnet_embedding_dim))\n",
    "        )\n",
    "\n",
    "        for i in range(1, postnet_n_convolutions - 1):\n",
    "            self.convolutions.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Comv1d(postnet_embedding_dim,\n",
    "                              postnet_embedding_dim,\n",
    "                              postnet_kernel_size, stride=1,\n",
    "                              padding=postnet_kernel_size // 2,\n",
    "                              dilation=1),\n",
    "                    nn.BatchNorm1d(postnet_embedding_dim))\n",
    "            )\n",
    "\n",
    "        self.convolutions.append(\n",
    "            nn.Sequential(\n",
    "                ConvNorm(postnet_embedding_dim, n_mel_channels,\n",
    "                         kernel_size=postnet_kernel_size, stride=1,\n",
    "                         padding=postnet_kernel_size // 2,\n",
    "                         dilation=1, w_init_gain='linear'),\n",
    "                nn.BatchNorm1d(n_mel_channels))\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.convolutions) - 1):\n",
    "            x = F.dropout(torch.tanh(self.convolutions[i](x)), \n",
    "                0.5, self.training)\n",
    "        x = F.dropout(self.convolutions[-1](x), 0.5, self.training)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Tacotron注意力机制\n",
    "class LocationLayer(nn.Module):\n",
    "    def __init__(self, attention_n_filters, attention_kernel_size,\n",
    "                 attention_dim):\n",
    "        super(LocationLayer, self).__init__()\n",
    "        padding = attention_kernel_size // 2\n",
    "        self.location_conv = nn.Conv2d(2, attention_n_filters,\n",
    "                                      kernel_size=attention_kernel_size,\n",
    "                                      padding=padding, bias=False, stride=1,\n",
    "                                      dilation=1)\n",
    "        self.location_dense = nn.Linear(attention_n_filters, attention_dim,\n",
    "                                        bias=False)\n",
    "\n",
    "    def forward(self, attention_weights_cat):\n",
    "        processed_attention = self.location_conv(attention_weights_cat)\n",
    "        processed_attention = processed_attention.transpose(1, 2)\n",
    "        processed_attention = self.location_dense(processed_attention)\n",
    "        return processed_attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, attention_rnn_dim, embedding_dim, attention_dim,\n",
    "                 attention_location_n_filters, \n",
    "                 attention_location_kernel_size):\n",
    "\n",
    "        super(Attention, self).__init__()\n",
    "        self.query_layer = nn.Linear(attention_rnn_dim,\n",
    "                                     attention_dim,bias=False)\n",
    "        self.memory_layer = nn.Linear(embedding_dim, \n",
    "                                      attention_dim, bias=False)\n",
    "\n",
    "        self.v = nn.Linear(attention_dim, 1, bias=False)\n",
    "        self.location_layer = LocationLayer(attention_location_n_filters,\n",
    "                                            attention_location_kernel_size,\n",
    "                                            attention_dim)\n",
    "        self.score_mask_value = -float(\"inf\")\n",
    "\n",
    "    def get_alignment_energies(self, query, processed_memory,\n",
    "                               attention_weights_cat):\n",
    "\n",
    "        processed_query = self.query_layer(query.unsqueeze(1))\n",
    "        processed_attention_weights = self.location_layer(\n",
    "                attention_weights_cat)\n",
    "        energies = self.v(torch.tanh(\n",
    "            processed_query + processed_attention_weights + \\\n",
    "            processed_memory))\n",
    "\n",
    "        energies = energies.squeeze(-1)\n",
    "        return energies\n",
    "\n",
    "    def forward(self, attention_hidden_state, memory, processed_memory,\n",
    "                attention_weights_cat, mask):\n",
    "\n",
    "        alignment = self.get_alignment_energies(\n",
    "            attention_hidden_state, processed_memory, \n",
    "            attention_weights_cat)\n",
    "\n",
    "        if mask is not None:\n",
    "            alignment.data.masked_fill_(mask, self.score_mask_value)\n",
    "\n",
    "        attention_weights = F.softmax(alignment, dim=1)\n",
    "        attention_context = torch.bmm(attention_weights.unsqueeze(1), \n",
    "                                      memory)\n",
    "        attention_context = attention_context.squeeze(1)\n",
    "\n",
    "        return attention_context, attention_weights\n",
    "\n",
    "# Tacotron解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_mel_channels, n_frames_per_step,\n",
    "        encoder_embedding_dim, attention_rnn_dim,\n",
    "        decoder_rnn_dim, prenet_dim, max_decoder_steps,\n",
    "        gate_threshold, p_attention_dropout,\n",
    "        attention_dim, attention_location_n_filters,\n",
    "        attention_location_kernel_size, p_decoder_dropout):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # 将输入参数保存到类的属性中\n",
    "        # ... （此处省略保存输入参数的代码）\n",
    "        self.prenet = Prenet(\n",
    "            n_mel_channels * n_frames_per_step,\n",
    "            [prenet_dim, prenet_dim])\n",
    "\n",
    "        self.attention_rnn = nn.LSTMCell(\n",
    "            prenet_dim + encoder_embedding_dim,\n",
    "            attention_rnn_dim)\n",
    "\n",
    "        self.attention_layer = Attention(\n",
    "            attention_rnn_dim, encoder_embedding_dim,\n",
    "            attention_dim, attention_location_n_filters,\n",
    "            attention_location_kernel_size)\n",
    "\n",
    "        self.decoder_rnn = nn.LSTMCell(\n",
    "            attention_rnn_dim + encoder_embedding_dim,\n",
    "            decoder_rnn_dim, 1)\n",
    "\n",
    "        self.linear_projection = nn.Linear(\n",
    "            decoder_rnn_dim + encoder_embedding_dim,\n",
    "            n_mel_channels * n_frames_per_step)\n",
    "\n",
    "        self.gate_layer = nn.Linear(\n",
    "            decoder_rnn_dim + encoder_embedding_dim, 1,\n",
    "            bias=True)\n",
    "\n",
    "    def decode(self, decoder_input):\n",
    "        # 输入解码器的梅尔过滤器特征，进行注意力机制的计算和循环神经网络计算\n",
    "        # 输出解码结果，即是否终止的预测和注意力的权重\n",
    "        cell_input = torch.cat((decoder_input, self.attention_context), -1)\n",
    "        self.attention_hidden, self.attention_cell = self.attention_rnn(\n",
    "            cell_input, (self.attention_hidden, self.attention_cell))\n",
    "        self.attention_hidden = F.dropout(\n",
    "            self.attention_hidden, self.p_attention_dropout, self.training)\n",
    "\n",
    "        attention_weights_cat = torch.cat(\n",
    "            (self.attention_weights.unsqueeze(1),\n",
    "             self.attention_weights_cum.unsqueeze(1)), dim=1)\n",
    "        self.attention_context, self.attention_weights = \\\n",
    "            self.attention_layer(self.attention_hidden,\n",
    "            self.memory, self.processed_memory,\n",
    "            attention_weights_cat, self.mask)\n",
    "\n",
    "        self.attention_weights_cum += self.attention_weights\n",
    "        decoder_input = torch.cat(\n",
    "            (self.attention_hidden, self.attention_context), -1)\n",
    "        self.decoder_hidden, self.decoder_cell = self.decoder_rnn(\n",
    "            decoder_input, (self.decoder_hidden, self.decoder_cell))\n",
    "        self.decoder_hidden = F.dropout(\n",
    "            self.decoder_hidden, self.p_decoder_dropout, self.training)\n",
    "\n",
    "        decoder_hidden_attention_context = torch.cat(\n",
    "            (self.decoder_hidden, self.attention_context), dim=1)\n",
    "        decoder_output = self.linear_projection(\n",
    "            decoder_hidden_attention_context)\n",
    "\n",
    "        gate_prediction = self.gate_layer(decoder_hidden_attention_context)\n",
    "        return decoder_output, gate_prediction, self.attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 以下代码仅作为WaveNet的实现参考\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 因果卷积模块\n",
    "class CausalConv(nn.Module):\n",
    "\n",
    "    def __init__(self, residual_channels, gate_channels, kernel_size,\n",
    "                 local_channels, dropout=0.05, dilation=1, bias=True):\n",
    "\n",
    "        super(CausalConv, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(residual_channels, gate_channels, \n",
    "                              kernel_size, padding=padding,\n",
    "                              dilation=dilation, bias=bias)\n",
    "\n",
    "        self.conv1x1_local = Conv1d1x1(local_channels,\n",
    "                                       gate_channels, bias=False)\n",
    "        gate_out_channels = gate_channels // 2\n",
    "        self.conv1x1_out = Conv1d1x1(gate_out_channels, \n",
    "                                     residual_channels, bias=bias)\n",
    "        self.conv1x1_skip = Conv1d1x1(gate_out_channels,\n",
    "                                      residual_channels, bias=bias)\n",
    "\n",
    "    def forward(self, x, x_local):\n",
    "\n",
    "        # x为音频信号，x_local为梅尔过滤器特征上采样到和x维度相同后的结果\n",
    "        # 假设输入x的大小为N×C×T，其中N为批次大小，C为输入特征大小，\n",
    "        # T为序列长度\n",
    "        # x_local大小和x大小相同\n",
    "\n",
    "        residual = x\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # 因果卷积\n",
    "        x = self.conv(x)\n",
    "        x = x[:, :, :residual.size(-1)]\n",
    "\n",
    "        # 因果卷积结果分割\n",
    "        a, b = x.split(x.size(-1) // 2, dim=-1)\n",
    "        # 加入局域特征的调制\n",
    "        c = self.conv1x1_local(x_local)\n",
    "        ca, cb = c.split(c.size(-1) // 2, dim=-1)\n",
    "        a, b = a + ca, b + cb\n",
    "\n",
    "        x = torch.tanh(a) * torch.sigmoid(b)\n",
    "\n",
    "        s = self.conv1x1_skip(x)\n",
    "        x = self.conv1x1_out(x)\n",
    "\n",
    "        x = (x + residual) * math.sqrt(0.5)\n",
    "        return x, s\n",
    "\n",
    "# WaveNet模型代码\n",
    "class WaveNet(nn.Module):\n",
    "\n",
    "    def __init__(self, out_channels=256, layers=20,\n",
    "                 layers_per_stack = 2,\n",
    "                 residual_channels=512,\n",
    "                 gate_channels=512,\n",
    "                 mel_channels = 80,\n",
    "                 mel_kernel = 1024,\n",
    "                 mel_stride = 256,\n",
    "                 skip_out_channels=512,\n",
    "                 kernel_size=3, dropout= 0.05,\n",
    "                 local_channels=512):\n",
    "\n",
    "        super(WaveNet, self).__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.local_channels = local_channels\n",
    "        self.first_conv = nn.Conv1d(out_channels, residual_channels, 1)\n",
    "\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for layer in range(layers):\n",
    "            dilation = 2**(layer % layers_per_stack)\n",
    "            conv = CausalConv(residual_channels, gate_channels, kernel_size,\n",
    "                              local_channels, dropout, dilation, True)\n",
    "            self.conv_layers.append(conv)\n",
    "        self.last_conv_layers = nn.ModuleList([\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(skip_out_channels, skip_out_channels, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(skip_out_channels, out_channels, 1),\n",
    "        ])\n",
    "\n",
    "        self.upsample_net = nn.ConvTranspose1d(mel_channels, gate_channels, \n",
    "                                               mel_kernel, mel_stride)\n",
    "\n",
    "    def forward(self, x, x_local):\n",
    "\n",
    "        # x为音频信号，x_local为梅尔过滤器特征\n",
    "        B, _, T = x.size()\n",
    "        # 对特征进行上采样，输出和音频信号长度相同的信号\n",
    "        c = self.upsample_net(x_local)\n",
    "        x = self.first_conv(x)\n",
    "        skips = 0\n",
    "        for f in self.conv_layers:\n",
    "            x, h = f(x, c, g_bct)\n",
    "            skips += h\n",
    "        skips *= math.sqrt(1.0 / len(self.conv_layers))\n",
    "\n",
    "        x = skips\n",
    "        for f in self.last_conv_layers:\n",
    "            x = f(x)\n",
    "\n",
    "        # 输出每个强度的概率\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 本代码仅作为Wide&Deep模型的实现参考\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WideDeep(nn.Module):\n",
    "    def __init__(self, num_wide_feat, deep_feat_sizes, \n",
    "        deep_feat_dims, nhiddens):\n",
    "\n",
    "        super(WideDeep, self).__init__()\n",
    "\n",
    "        self.num_wide_feat = num_wide_feat\n",
    "        self.deep_feat_sizes = deep_feat_sizes\n",
    "        self.deep_feat_dims = deep_feat_dims\n",
    "        self.nhiddens = nhiddens\n",
    "\n",
    "        # 深模型的嵌入部分\n",
    "        self.embeds = nn.ModuleList()\n",
    "        for deep_feat_size, deep_feat_dim in \\\n",
    "            zip(deep_feat_sizes, deep_feat_dims):\n",
    "            self.embeds.append(nn.Embedding(deep_feat_size, \n",
    "                deep_feat_dim))\n",
    "\n",
    "        self.deep_input_size = sum(deep_feat_dims)\n",
    "\n",
    "        # 深模型的线性部分 \n",
    "        self.linears = nn.ModuleList()\n",
    "        in_size = self.deep_input_size\n",
    "        for out_size in nhiddens:\n",
    "            self.linears.append(nn.Linear(in_size, out_size))\n",
    "            in_size = out_size\n",
    "\n",
    "        # 宽模型和深模型共同的线性部分 \n",
    "        self.proj = nn.Linear(in_size + num_wide_feat, 1)\n",
    "\n",
    "    def forward(self, wide_input, deep_input):\n",
    "        \n",
    "        # 假设宽模型的输入为N×W，N为迷你批次的大小，W为宽特征的大小\n",
    "        # 假设深模型的输入为N×D，N为迷你批次的大小，D为深特征的数目\n",
    "        embed_feats = []\n",
    "        for i in range(deep_input.size(1)):\n",
    "            embed_feats.append(self.embeds[i](deep_input[:, i]))\n",
    "        deep_feats = torch.cat(embed_feats, 1)\n",
    "        \n",
    "        # 深模型特征变换\n",
    "        for layer in self.linears:\n",
    "            deep_feats = layer(deep_feats)\n",
    "            deep_feats = torch.relu(deep_feats)\n",
    "        print(wide_input.shape, deep_feats.shape)\n",
    "\n",
    "        # 宽模型和深模型特征拼接\n",
    "        wide_deep_feats = torch.cat([wide_input, deep_feats], -1)\n",
    "        return torch.sigmoid(self.proj(wide_deep_feats)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 静态模型的保存和载入\n",
    "from torchvision.models import resnet18\n",
    "m = resnet18(pretrained=True)\n",
    "# 将模型从动态图转换为静态图\n",
    "static_model = torch.jit.trace(m, torch.randn(1, 3, 224, 224))\n",
    "# 保存模型\n",
    "torch.jit.save(static_model, \"resnet18.pt\")\n",
    "# 读取模型\n",
    "static_model = torch.load(\"resnet18.pt\")\n",
    "\n",
    "# 导出到ONNX\n",
    "from torchvision.models import resnet18\n",
    "# 需要使用pip install onnx安装onnx的Python接口\n",
    "import onnx\n",
    "m = resnet18(pretrained=True)\n",
    "torch.onnx.export(m, torch.randn(1, 3, 224, 224), \n",
    "                  \"resnet18.onnx\", verbose=True)\n",
    "# 用onnx读入模型\n",
    "m = onnx.load(\"resnet18.onnx\")\n",
    "# 检查模型正确性\n",
    "onnx.checker.check_model(m)\n",
    "# 打印计算图\n",
    "onnx.helper.printable_graph(m.graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C语言代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <torch/torch.h>\n",
    "#include <torch/script.h>\n",
    "\n",
    "int main() {\n",
    "    auto mod = torch::jit::load(\"resnet18.pt\");\n",
    "    std::vector<torch::jit::IValue> inputs;\n",
    "    inputs.push_back(torch::randn({1, 3, 224, 224}));\n",
    "    std::cout<<mod.forward(inputs).toTensor().argmax(1)<<std::endl;\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 静态加载\n",
    "import torch\n",
    "import gelu\n",
    "\n",
    "# 同样可以通过 gelu = GELU.apply使用这个激活函数\n",
    "class GELU(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        return gelu.forward(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input = ctx.input\n",
    "        return gelu.backward(grad_output, input)\n",
    "\n",
    "# 动态加载\n",
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "# PyTorch会进行自动编译，生成对应的模块\n",
    "gelu = load(name=\"gelu\", sources=[\"gelu/gelu.cc\"])\n",
    "\n",
    "class GELU(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        return gelu.forward(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input = ctx.input\n",
    "        return gelu.backward(grad_output, input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 本代码仅作为钩子函数的演示代码\n",
    "\"\"\"\n",
    "\n",
    "# 模块执行之前的前向计算钩子的定义\n",
    "# 定义nn.Module的一个实例模块\n",
    "module = ...\n",
    "def hook(module, input):\n",
    "    # 对模块权重或者输入进行操作的代码\n",
    "    # 函数结果可以返回修改后的张量或者None\n",
    "    return input\n",
    "handle = module.register_forward_pre_hook(hook)\n",
    "\n",
    "# 模块执行之后的前向计算钩子的定义\n",
    "# 定义nn.Module的一个实例模块\n",
    "module = ...\n",
    "def hook(module, input, output):\n",
    "    # 对模块权重或者输入/输出进行操作的代码\n",
    "    # 函数结果可以返回修改后的张量或者None\n",
    "    return output\n",
    "handle = module.register_forward_hook(hook)\n",
    "\n",
    "# 模块执行之后的反向传播钩子的定义\n",
    "# 定义nn.Module的一个实例模块\n",
    "module = ...\n",
    "def hook(module, grad_input, grad_output):\n",
    "    # 对模块权重或者输入/输出梯度进行操作的代码\n",
    "    # 函数结果可以返回修改后的张量或者None\n",
    "    return output\n",
    "handle = module.register_backward_hook(hook)\n",
    "\n",
    "# 钩子的使用方法示例\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "def print_pre_shape(module, input):\n",
    "    print(\"模块前钩子\")\n",
    "    print(module.weight.shape)\n",
    "    print(input[0].shape)\n",
    "def print_post_shape(module, input, output):\n",
    "    print(\"模块后钩子\")\n",
    "    print(module.weight.shape)\n",
    "    print(input[0].shape)\n",
    "    print(output[0].shape)\n",
    "def print_grad_shape(module, grad_input, grad_output):\n",
    "    print(\"梯度钩子\")\n",
    "    print(module.weight.grad.shape)\n",
    "    print(grad_input[0].shape)\n",
    "    print(grad_output[0].shape)\n",
    "conv = nn.Conv2d(16, 32, kernel_size=(3,3))\n",
    "handle1 = conv.register_forward_pre_hook(print_pre_shape)\n",
    "handle2 = conv.register_forward_hook(print_post_shape)\n",
    "handle3 = conv.register_backward_hook(print_grad_shape)\n",
    "input = torch.randn(4, 16, 128, 128, requires_grad=True)\n",
    "ret = conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 本代码仅供参考\n",
    "\"\"\"\n",
    "\n",
    "# jit.trace函数的签名\n",
    "torch.jit.trace(func, example_inputs, optimize=None, \n",
    "                check_trace=True, check_inputs=None, check_tolerance=1e-5)\n",
    "\n",
    "def func(a):\n",
    "    return a.pow(2) + 1\n",
    "\n",
    "class Mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mod, self).__init__()\n",
    "\n",
    "    def forward(self, a):\n",
    "        return a.pow(2) + 1\n",
    "\n",
    "ret = torch.jit.trace(func, torch.randn(3,3))\n",
    "print(ret.graph)\n",
    "# 打印出的值：\n",
    "# graph(%a : Float(3, 3)):\n",
    "#   %1 : int = prim::Constant[value=2]() \n",
    "#   %2 : Float(3, 3) = aten::pow(%a, %1)\n",
    "#   %3 : Long() = prim::Constant[value={1}]()\n",
    "#   %4 : int = prim::Constant[value=1]() \n",
    "#   %5 : Float(3, 3) = aten::add(%2, %3, %4) \n",
    "#  return (%5)\n",
    "m = Mod()\n",
    "ret = torch.jit.trace(m, torch.randn(3,3))\n",
    "print(ret.graph)\n",
    "# 打印出的值：\n",
    "# graph(%self : ClassType<Mod>,\n",
    "#       %a : Float(3, 3)):\n",
    "#   %2 : int = prim::Constant[value=2](), scope: Mod #\n",
    "#   %3 : Float(3, 3) = aten::pow(%a, %2), scope: Mod #\n",
    "#   %4 : Long() = prim::Constant[value={1}](), scope: Mod\n",
    "#   %5 : int = prim::Constant[value=1](), scope: Mod\n",
    "#   %6 : Float(3, 3) = aten::add(%3, %4, %5), scope: Mod\n",
    "#   return (%6)\n",
    "\n",
    "# jit.trace_module函数的签名\n",
    "torch.jit.trace_module(mod, inputs, optimize=None, check_trace=True,\n",
    "                       check_inputs=None, check_tolerance=1e-5)\n",
    "\n",
    "class Mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mod, self).__init__()\n",
    "\n",
    "    def forward(self, a):\n",
    "        return a.pow(2) + 1\n",
    "    \n",
    "    def square(self, a):\n",
    "        return a.pow(2)\n",
    "\n",
    "trace_input = {\"forward\": torch.randn(3,3), \"square\": torch.randn(3,3)}\n",
    "m = Mod()\n",
    "ret = torch.jit.trace_module(m, trace_input)\n",
    "print(ret.forward.graph) # 和前面的torch.jit.trace函数输出的结果相同\n",
    "print(ret.square.graph)\n",
    "# 打印出的值：\n",
    "# graph(%self : ClassType<Mod>,\n",
    "#       %a : Float(3, 3)):\n",
    "#  %2 : int = prim::Constant[value=2]() #  %3 : Float(3, 3) = aten::pow(%a, %2)\n",
    "#  return (%3)\n",
    "\n",
    "# 使用torch.jit.script方法进行修饰\n",
    "# 也可以使用 @torch.jit.script 对函数进行装饰\n",
    "def func(a):\n",
    "    if a.norm() > 1.0:\n",
    "        return a.abs()\n",
    "    else:\n",
    "        return a.pow(2)\n",
    "\n",
    "ret = torch.jit.script(func)\n",
    "print(ret.graph)\n",
    "# 打印出的值：\n",
    "# graph(%a.1 : Tensor):\n",
    "#   %4 : float = prim::Constant[value=1]()\n",
    "#   %10 : int = prim::Constant[value=2]()\n",
    "#   %3 : Tensor = aten::norm(%a.1, %10)\n",
    "#   %5 : Tensor = aten::gt(%3, %4)\n",
    "#   %6 : bool = aten::Bool(%5)\n",
    "#   %18 : Tensor = prim::If(%6)\n",
    "#     block0():\n",
    "#       %8 : Tensor = aten::abs(%a.1)\n",
    "#       -> (%8)\n",
    "#     block1():\n",
    "#       %11 : Tensor = aten::pow(%a.1, %10) # -> (%11)\n",
    "#   return (%18)\n",
    "\n",
    "class Mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mod, self).__init__()\n",
    "\n",
    "    # 默认行为: torch.jit.export\n",
    "    def forward(self, a):\n",
    "        if a.norm() > 1.0:\n",
    "            return a.abs()\n",
    "        else:\n",
    "            return a.pow(2)\n",
    "\n",
    "    # 导出该方法\n",
    "    @torch.jit.export\n",
    "    def square(self, a):\n",
    "        return a.pow(2)\n",
    "\n",
    "    # 不导出该方法\n",
    "    @torch.jit.ignore\n",
    "    def abs(self, a):\n",
    "        return a.abs()\n",
    "\n",
    "mod = Mod()\n",
    "ret = torch.jit.script(mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
